It has been almost 20 years since IBM's Deep Blue supercomputer beat the reigning world champion for the first time under standard tournament rules. Computers have become much stronger over the years leaving human opposition little chance but they still rely on brute force to choose the best move. Matthew Lai at Imperial College London has created an artificial intelligence machine called Giraffe that has taught itself to play chess at an international level within 72 hours by evaluating chess positions much more like humans. Lai's machine uses a neural network which consists of 4 layers of nodes connected in a way that changes as the system is trained. It examines each position on the board in three different ways. The first looks at the global state of the game, such as the number and type of pieces on each side, which side is to move, castling rights and so on. The second looks at piece-centric features such as the location of each piece on each side, while the final aspect is to map the squares that each piece attacks and defends. He trains his network with a carefully generated set of data taken from real chess games. This data set must have the correct distribution of positions, "It doesn't make sense to train the system on positions with three queens per side, because those positions virtually never come up in actual games." Lai generated his dataset by randomly choosing five million positions from a database of computer chess games. He then created greater variety by adding a random legal move to each position before using it for training. In total he generated 175 million positions in this way. The usual way of training these machines is to manually evaluate every position and use this information to teach the machine to recognize those that are strong and those that are weak. But this is a huge task for 175 million positions. It could be done by another chess engine but Lai's goal was more ambitious. He wanted the machine to learn itself. Instead, he used a bootstrapping technique in which Giraffe played against itself with the goal of improving its prediction of its own evaluation of a future position. That works because there are fixed reference points that ultimately determine the value of a position - whether the game is later won, lost or drawn. In this way, the computer learns which positions are strong and which are weak. Having trained Giraffe, the final step is to test it and here the results make for interesting reading. Lai tested his machine on a standard database called the Strategic Test Suite, which consists of 1,500 positions that are chosen to test an engine's ability to recognize different strategic ideas. The results of this test are scored out of 15,000. Lai uses this to test the machine at various stages during its training. As the bootstrapping process begins, Giraffe quickly reaches a score of 6,000 and eventually peaks at 9,700 after only 72 hours. Lai says that matches the best chess engines in the world. Unfortunately Giraffe takes about 10 times longer than a conventional chess engine to search the same number of positions.
