Computer uses Machine Learning techniques to teach itself Chess

In 1996 IBM's supercomputer Deep Blue was the first to beat a grand-master in a game of chess. Since then computers have only improved in their chess playing ability. However, at their base, all chess playing algorithms still rely on brute force techniques to analyse possible future permutations of the game. This year a research group lead by Matthew Lai at Imperial College London created a computer, named Giraffe, which used a neural network to better understand chess moves. Lai generated a dataset of 5 million chess board positions from a database of computer chess games. He also ensured that this dataset had the correct distribution of chess board positions, ensuring less rare arrangements and more common chess positions. Lai also took each generated position and added some random legal moves to generate a final dataset of 175 million positions. Lai wanted Giraffe to learn by itself and so, instead of getting other chess playing computers to evaluate Giraffe's chess moves, he had Giraffe play against itself. This process allowed the machine to learn which kinds of moves, from particular board arrangements, would be more likely to lead to an eventual victory. This machine learning technique means that Giraffe can tell when a given move is not worth investigating, exponentially reducing the number of branches that need to be searched and analysed compared to traditional algorithms. This techniques much more closely models a human player's in that only a small number of possible moves, and how they will effect the future of the game, have to be analysed whilst still maintaining a high chance of eventually winning the game.
